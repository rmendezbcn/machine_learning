---
title: "machine_learning_project"
author: "Raul Mendez-Vasquez"
date: "12/11/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Classificating exercises using data from portable devices

The goal of this project is to predict what exercise the volunteers are performing based on the data recorded by portable devices such as the reading of <b>gyroscopes</b> and <b>accelerometers</b>.
<p>The objective of the experiment was to assess how well a group of 6 volunteers performed a weight lifting exercise.</p>
<p>The 6 six male participants, aged between 20-28 years, selected for the study were asked to perform the same weight lifting exercise in 5 different manners:</p>
  <li>Exactly according to the specification (Class A)</li> 
  <li>Throwing the elbows to the front (Class B)</li>
  <li>Lifting the dumbbell only halfway (Class C)</li>
  <li>lowering the dumbbell only halfway (Class D)</li>
  <li>throwing the hips to the front (Class E)</li>


br
<p>The goal of this learning machine learning project is to classify the activity based on the data produced in this study.</p>

<h2>Methods</h2>
<h3>Placement of the sensors</h3>
<p>The sensors were placed on all the volunteers according to the schema shown below.</p>

```{r echo=FALSE}
library(png)
knitr::include_graphics(path = "figure/on-body-sensing-schema.png")
```

<h3>Variable selections</h3>
<p>The majority of the variables in the training data set consisted of calculated variables, and only few corresponded to the data produced by the sensors in the mobile devices.</p>
<p>Only the variables containing raw data from the sensors were selected for this project. The selection was done using the grep function on the name of the variables<p>
``` {r eval= FALSE}
var_names <- names(intrain)
selected_vars <- var_names[grep('^accel|^gyros|^magnet|^roll|^pitch|^yaw|^classe', var_names)]
train_set <- subset(intrain, select = selected_vars)
```
<h3>Model building</h3
Two partitions were created to enable testing the model.
``` {r eval= FALSE}
intrain_set <- createDataPartition(y = intrain$classe, p = 0.7, list = FALSE) 

train_set <- intrain[ intrain_set, ]
test_set <- intrain[-intrain_set, ]
```

<h3>Cross validation</h3>
<p>The cross validation was performed applying the k-fold method: 10 times and 5 repetitions. </p>

<p>A random forest was the model selected for the project. </p>
``` {r eval = FALSE}
control <- trainControl(method = "repeatedcv", repeats = 5)
rfmodfit <- train(classe ~., data = train_set, method = "rpart", trControl = control)
```

<h2>Testing the model</h2>
The model was tested using the sub-partition "test_set" created from the initial training data set.
``` {r eval = FALSE}
pred1 <- predict(rfmodfit, test_set)
table(pred1, test_set$classe)
confusionMatrix(pred1, test_set$classe)
```

<h2>Results</h2>
The accuracy of the model was lower than 0.5, suggesting that a random selection could have perfomred better than the actual model. I
``` {r echo = FALSE}
knitr::include_graphics(path = "figure/class_tree_project.png")
```

<h2>Discussion</h2>
<p>The accuracy of the resulting model was lower than 0.5, for which should be rejected. As a random classification of the cases in the test set would performed better than the actual model. The observed accuracy is likey the result of an incorrect selection of the variables, a process that most be reviewed in detail. However, the decision tree seemed coherent with the idea that the exercises in classes B to E were deviations from the pattern observed in the class A, i.et. when performing the exercise in the correct way. Also because the classes B to E show up when different cutoff values were applied to the data. Thus, class A and class E (throwing the hips to the front) were split with the data from the belt; 
the class B (throwing the elbows to the front) was identified using the “y” direction of the magnet dumbbell; and finally the class C (lifting the dumbbell only halfway) was split from the class A 
whit sensor in the forearm. The resulting classification tree is shown in the following Figure.</p>

In conclussion the model most be rejected and new approaches to select the variables most be applied in order to achieve greater accuracy.
br










